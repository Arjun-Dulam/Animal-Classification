{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessImage(imagePath):\n",
    "    image = cv2.imread(imagePath) # loads pixel values\n",
    "    image = cv2.resize(image, (256, 256)) # resizes to be square shape\n",
    "    image = image / 255.0 # normalizes the light values, so the pixel values range from 0 to 1.\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n",
      "[[[0.51372549 0.8627451  0.82745098]\n",
      "  [0.5372549  0.87843137 0.85882353]\n",
      "  [0.56078431 0.89019608 0.87843137]\n",
      "  ...\n",
      "  [0.18039216 0.76078431 0.68235294]\n",
      "  [0.17647059 0.76078431 0.68235294]\n",
      "  [0.17647059 0.76078431 0.68235294]]\n",
      "\n",
      " [[0.50980392 0.85882353 0.82352941]\n",
      "  [0.54117647 0.87843137 0.85882353]\n",
      "  [0.56078431 0.89019608 0.87843137]\n",
      "  ...\n",
      "  [0.18431373 0.76078431 0.68235294]\n",
      "  [0.17647059 0.76078431 0.68235294]\n",
      "  [0.17647059 0.76078431 0.68235294]]\n",
      "\n",
      " [[0.50980392 0.85882353 0.82352941]\n",
      "  [0.54117647 0.87843137 0.85882353]\n",
      "  [0.56078431 0.89019608 0.87843137]\n",
      "  ...\n",
      "  [0.18431373 0.76078431 0.68235294]\n",
      "  [0.17647059 0.76078431 0.68235294]\n",
      "  [0.17647059 0.76078431 0.68235294]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.18823529 0.85098039 0.78039216]\n",
      "  [0.17254902 0.84313725 0.78039216]\n",
      "  [0.15686275 0.84705882 0.78039216]\n",
      "  ...\n",
      "  [0.38431373 0.81960784 0.74117647]\n",
      "  [0.4        0.82352941 0.74901961]\n",
      "  [0.40784314 0.82745098 0.75294118]]\n",
      "\n",
      " [[0.25882353 0.85490196 0.79607843]\n",
      "  [0.23137255 0.85490196 0.79215686]\n",
      "  [0.19607843 0.85490196 0.78823529]\n",
      "  ...\n",
      "  [0.38823529 0.81960784 0.74117647]\n",
      "  [0.40392157 0.82352941 0.74901961]\n",
      "  [0.41176471 0.83137255 0.75686275]]\n",
      "\n",
      " [[0.32941176 0.86666667 0.81568627]\n",
      "  [0.29411765 0.86666667 0.81176471]\n",
      "  [0.24705882 0.8627451  0.8       ]\n",
      "  ...\n",
      "  [0.38823529 0.81960784 0.74509804]\n",
      "  [0.40392157 0.82745098 0.75294118]\n",
      "  [0.41176471 0.83137255 0.75686275]]]\n"
     ]
    }
   ],
   "source": [
    "array = np.array(preprocessImage(\"images/butterfly/e030b20a20e90021d85a5854ee454296eb70e3c818b413449df6c87ca3ed_640.jpg\"))\n",
    "print(array.shape)\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def initialize_parameters():\n",
    "    # weights = np.random.rand(1,n) # creates a 1 x n array of values where n is the number of features in the input."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessImage(imagePath):\n",
    "\n",
    "    with Image.open(imagePath) as img:\n",
    "        img = img.convert('RGB')\n",
    "        img.save(imagePath) \n",
    "    # This ensures that the image is saved in a format that can be read by OpenCV\n",
    "    image = cv2.imread(imagePath) # loads pixel values\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # converts from BGR to RGB format\n",
    "    image = cv2.resize(image, (256, 256)) # resizes to be square shape\n",
    "    image  = cv2.bilateralFilter(image, 9, 75, 75) # applies a bilateral filter to smooth the image while preserving edges\n",
    "    image = image / 255.0 # normalizes the light values, so the pixel values range from 0 to 1.\n",
    "\n",
    "    \n",
    "    return image\n",
    "\n",
    "def showImage(image):\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeParameters(n, m):\n",
    "    \"\"\"\"\n",
    "    \"Initializes the parameters for a neural network layer with n inputs and m outputs.\n",
    "    \"\"\"\n",
    "    w = np.random.randn(n, m) * 0.01  \n",
    "    b = np.zeros((1, m)) \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(x, w, b):\n",
    "    \"\"\"\n",
    "    Computes the output of a linear layer given input x, weights w, and bias b.\n",
    "    x: input data (1,n)\n",
    "    w: weights (n,m)\n",
    "    b: bias (1,m)\n",
    "    \n",
    "    Returns the output (1,m) as a numpy array with softmax function applied.\n",
    "    \"\"\"\n",
    "    y = x @ w + b  # matrix multiplication and bias addition\n",
    "\n",
    "    # Apply softmax to the output\n",
    "    exp_y = np.exp(y - np.max(y))  # Subtract max for numerical stability\n",
    "    return exp_y / np.sum(exp_y, axis = 1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossEntropyLoss(y_out, y_true):\n",
    "    m = y_true.shape[0]  # number of samples in the batch\n",
    "    log_probs = np.log(y_out)\n",
    "    loss = -np.sum(y_true * log_probs) / m  # Average loss over all samples in the batch\n",
    "    return loss\n",
    "\n",
    "\n",
    "def gradient(y_out, y_true):\n",
    "    \"\"\"\n",
    "    Computes the gradient of the output using logistic regression.\n",
    "\n",
    "    \"\"\"\n",
    "    gradient = y_out - y_true\n",
    "    return gradient\n",
    "\n",
    "def updateParameters(w, b, gradient, learning_rate=0.01):\n",
    "    \"\"\"\n",
    "    Updates the weights and bias using the gradient and learning rate.\n",
    "    \"\"\"\n",
    "    \n",
    "    w -= learning_rate * gradient\n",
    "    b -= learning_rate * np.mean(gradient, axis=0) \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    animalTypes = os.listdir(folder)\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for index, animal in enumerate(animalTypes):\n",
    "        if animal.startswith('.'):\n",
    "            continue\n",
    "        animalPath = os.path.join(folder, animal)\n",
    "\n",
    "        if os.path.isdir(animalPath):\n",
    "            for filename in os.listdir(animalPath):\n",
    "                if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "                    imagePath = os.path.join(animalPath, filename)\n",
    "                    image = preprocessImage(imagePath)\n",
    "                    images.append(image)\n",
    "\n",
    "                    # Create and append one-hot encoded label\n",
    "                    label_one_hot = np.zeros(len(animalTypes))\n",
    "                    label_one_hot[index] = 1\n",
    "                    labels.append(label_one_hot)\n",
    "                    count += 1\n",
    "            print(f\"Processed {count} images from {animal}\")\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_minibatches(images, labels, batch_size=32, num_epochs=10, learning_rate=0.01):\n",
    "    input_size = images.shape[1] * images.shape[2] * images.shape[3]\n",
    "    num_classes = labels.shape[1]\n",
    "    w, b = initializeParameters(input_size, num_classes)\n",
    "\n",
    "    images = images.reshape(images.shape[0], -1)  # Flatten images\n",
    "\n",
    "    num_samples = images.shape[0]\n",
    "    for epoch in range(num_epochs):\n",
    "        # Shuffle data for each epoch (important for good generalization)\n",
    "        indices = np.random.permutation(num_samples)\n",
    "        images = images[indices]\n",
    "        labels = labels[indices]\n",
    "\n",
    "        # Mini-batch processing\n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            # Create a mini-batch\n",
    "            batch_images = images[i:i + batch_size]\n",
    "            batch_labels = labels[i:i + batch_size]\n",
    "\n",
    "            # Forward pass\n",
    "            y_out = output(batch_images, w, b)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = crossEntropyLoss(y_out, batch_labels)\n",
    "\n",
    "            # Backpropagation and gradient computation\n",
    "            grad = gradient(y_out, batch_labels)\n",
    "\n",
    "            # Update parameters\n",
    "            w, b = updateParameters(w, b, grad, learning_rate)\n",
    "\n",
    "        # Print loss for each epoch\n",
    "        print(f\"Epoch {epoch}/{num_epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "    return w, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 441 images from cat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 903 images from butterfly\n",
      "Processed 903 images from dog\n",
      "Processed 1279 images from sheep\n",
      "Processed 1603 images from spider\n",
      "Processed 1603 images from chicken\n",
      "Processed 1603 images from horse\n",
      "Processed 1603 images from squirrel\n",
      "Processed 1603 images from cow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1970 images from elephant\n",
      "Images shape: (1970, 256, 256, 3)\n",
      "Labels shape: (1970, 11)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (196608,11) (32,11) (196608,11) ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLabels shape:\u001b[39m\u001b[33m\"\u001b[39m, labels.shape)  \u001b[38;5;66;03m# Should be (num_images, num_classes)\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Train the model using mini-batches\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m w, b = \u001b[43mtrain_with_minibatches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mtrain_with_minibatches\u001b[39m\u001b[34m(images, labels, batch_size, num_epochs, learning_rate)\u001b[39m\n\u001b[32m     28\u001b[39m     grad = gradient(y_out, batch_labels)\n\u001b[32m     30\u001b[39m     \u001b[38;5;66;03m# Update parameters\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     w, b = \u001b[43mupdateParameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Print loss for each epoch\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mupdateParameters\u001b[39m\u001b[34m(w, b, gradient, learning_rate)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupdateParameters\u001b[39m(w, b, gradient, learning_rate=\u001b[32m0.01\u001b[39m):\n\u001b[32m     17\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[33;03m    Updates the weights and bias using the gradient and learning rate.\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     \u001b[43mw\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\n\u001b[32m     22\u001b[39m     b -= learning_rate * np.mean(gradient, axis=\u001b[32m0\u001b[39m) \n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m w, b\n",
      "\u001b[31mValueError\u001b[39m: operands could not be broadcast together with shapes (196608,11) (32,11) (196608,11) "
     ]
    }
   ],
   "source": [
    "# Load images and labels\n",
    "images, labels = load_images(\"images\")\n",
    "print(\"Images shape:\", images.shape)  # Should be (num_images, 256, 256, 3)\n",
    "print(\"Labels shape:\", labels.shape)  # Should be (num_images, num_classes)\n",
    "\n",
    "# Train the model using mini-batches\n",
    "w, b = train_with_minibatches(images, labels, batch_size=32, num_epochs=10, learning_rate=0.01)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

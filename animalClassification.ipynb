{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessImage(imagePath):\n",
    "\n",
    "    with Image.open(imagePath) as img:\n",
    "        img = img.convert('RGB')\n",
    "        img.save(imagePath) \n",
    "    # This ensures that the image is saved in a format that can be read by OpenCV\n",
    "    image = cv2.imread(imagePath) # loads pixel values\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # converts from BGR to RGB format\n",
    "    image = cv2.resize(image, (256, 256)) # resizes to be square shape\n",
    "    image  = cv2.bilateralFilter(image, 9, 75, 75) # applies a bilateral filter to smooth the image while preserving edges\n",
    "    image = image / 255.0 # normalizes the light values, so the pixel values range from 0 to 1.\n",
    "\n",
    "    \n",
    "    return image\n",
    "\n",
    "def showImage(image):\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeParameters(n, m):\n",
    "    \"\"\"\"\n",
    "    \"Initializes the parameters for a neural network layer with n inputs and m outputs.\n",
    "    \"\"\"\n",
    "    w = np.random.randn(n, m) * 0.01  \n",
    "    b = np.zeros((1, m)) \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(x, w, b):\n",
    "    \"\"\"\n",
    "    Computes the output of a linear layer given input x, weights w, and bias b.\n",
    "    x: input data (1,n)\n",
    "    w: weights (n,m)\n",
    "    b: bias (1,m)\n",
    "    \n",
    "    Returns the output (1,m) as a numpy array with softmax function applied.\n",
    "    \"\"\"\n",
    "    y = x @ w + b  # matrix multiplication and bias addition\n",
    "\n",
    "    # Apply softmax to the output\n",
    "    exp_y = np.exp(y - np.max(y))  # Subtract max for numerical stability\n",
    "    return exp_y / np.sum(exp_y, axis = 1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossEntropyLoss(y_out, y_true):\n",
    "    m = y_true.shape[0]  # number of samples in the batch\n",
    "    log_probs = np.log(y_out)\n",
    "    loss = -np.sum(y_true * log_probs) / m  # Average loss over all samples in the batch\n",
    "    return loss\n",
    "\n",
    "\n",
    "def gradient(y_out, y_true):\n",
    "    \"\"\"\n",
    "    Computes the gradient of the output using logistic regression.\n",
    "\n",
    "    \"\"\"\n",
    "    gradient = y_out - y_true\n",
    "    return gradient\n",
    "\n",
    "def updateParameters(w, b, gradient, learning_rate=0.01):\n",
    "    \"\"\"\n",
    "    Updates the weights and bias using the gradient and learning rate.\n",
    "    \"\"\"\n",
    "    \n",
    "    w -= learning_rate * gradient\n",
    "    b -= learning_rate * np.mean(gradient, axis=0) \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 441 images from cat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 903 images from butterfly\n",
      "Processed 903 images from dog\n",
      "Processed 1279 images from sheep\n"
     ]
    }
   ],
   "source": [
    "def load_images(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    animalTypes = os.listdir(folder)\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for index, animal in enumerate(animalTypes):\n",
    "        if animal.startswith('.'):\n",
    "            continue\n",
    "        animalPath = os.path.join(folder, animal)\n",
    "\n",
    "        if os.path.isdir(animalPath):\n",
    "            for filename in os.listdir(animalPath):\n",
    "                if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "                    imagePath = os.path.join(animalPath, filename)\n",
    "                    image = preprocessImage(imagePath)\n",
    "                    images.append(image)\n",
    "\n",
    "                    # Create and append one-hot encoded label\n",
    "                    label_one_hot = np.zeros(len(animalTypes))\n",
    "                    label_one_hot[index] = 1\n",
    "                    labels.append(label_one_hot)\n",
    "                    count += 1\n",
    "            print(f\"Processed {count} images from {animal}\")\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Example usage\n",
    "images, labels = load_images(\"images\")\n",
    "print(\"Images shape:\", images.shape)\n",
    "print(\"Labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_minibatches(images, labels, batch_size=32, num_epochs=10, learning_rate=0.01):\n",
    "    input_size = images.shape[1] * images.shape[2] * images.shape[3]\n",
    "    num_classes = labels.shape[1]\n",
    "    w, b = initializeParameters(input_size, num_classes)\n",
    "\n",
    "    images = images.reshape(images.shape[0], -1)  # Flatten images\n",
    "\n",
    "    num_samples = images.shape[0]\n",
    "    for epoch in range(num_epochs):\n",
    "        # Shuffle data for each epoch (important for good generalization)\n",
    "        indices = np.random.permutation(num_samples)\n",
    "        images = images[indices]\n",
    "        labels = labels[indices]\n",
    "\n",
    "        # Mini-batch processing\n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            # Create a mini-batch\n",
    "            batch_images = images[i:i + batch_size]\n",
    "            batch_labels = labels[i:i + batch_size]\n",
    "\n",
    "            # Forward pass\n",
    "            y_out = output(batch_images, w, b)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = crossEntropyLoss(y_out, batch_labels)\n",
    "\n",
    "            # Backpropagation and gradient computation\n",
    "            grad = gradient(y_out, batch_labels)\n",
    "\n",
    "            # Update parameters\n",
    "            w, b = updateParameters(w, b, grad, learning_rate)\n",
    "\n",
    "        # Print loss for each epoch\n",
    "        print(f\"Epoch {epoch}/{num_epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "    return w, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and labels\n",
    "images, labels = load_images(\"images\")\n",
    "print(\"Images shape:\", images.shape)  # Should be (num_images, 256, 256, 3)\n",
    "print(\"Labels shape:\", labels.shape)  # Should be (num_images, num_classes)\n",
    "\n",
    "# Train the model using mini-batches\n",
    "w, b = train_with_minibatches(images, labels, batch_size=32, num_epochs=10, learning_rate=0.01)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
